{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#Face Recognition with Facebook DeepFace Model\n",
    "#Author Sefik Ilkin Serengil (sefiks.com)\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_size = (152, 152)\n",
    "\n",
    "#OpenCV haarcascade module\n",
    "\n",
    "opencv_home = cv2.__file__\n",
    "folders = opencv_home.split(os.path.sep)[0:-1]\n",
    "path = folders[0]\n",
    "for folder in folders[1:]:\n",
    "\tpath = path + \"/\" + folder\n",
    "\n",
    "detector_path = path+\"/data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "if os.path.isfile(detector_path) != True:\n",
    "\traise ValueError(\"Confirm that opencv is installed on your environment! Expected path \",detector_path,\" violated.\")\n",
    "else:\n",
    "\tface_cascade = cv2.CascadeClassifier(detector_path)\n",
    "\n",
    "#-------------------------\n",
    "def detectFace(img_path, target_size=(152, 152)):\n",
    "\t\n",
    "\timg = cv2.imread(img_path)\n",
    "\t\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tif len(faces) > 0:\n",
    "\t\tx,y,w,h = faces[0]\n",
    "\t\t\n",
    "\t\tmargin = 0\n",
    "\t\tx_margin = w * margin / 100\n",
    "\t\ty_margin = h * margin / 100\n",
    "\t\t\n",
    "\t\tif y - y_margin > 0 and y+h+y_margin < img.shape[1] and x-x_margin > 0 and x+w+x_margin < img.shape[0]:\n",
    "\t\t\tdetected_face = img[int(y-y_margin):int(y+h+y_margin), int(x-x_margin):int(x+w+x_margin)]\n",
    "\t\telse:\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "\t\t\n",
    "\t\tdetected_face = cv2.resize(detected_face, target_size)\n",
    "\t\t\n",
    "\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\n",
    "\t\t#normalize in [0, 1]\n",
    "\t\timg_pixels /= 255 \n",
    "\t\t\n",
    "\t\treturn img_pixels\n",
    "\telse:\n",
    "\t\traise ValueError(\"Face could not be detected in \", img_path,\". Please confirm that the picture is a face photo.\")\n",
    "\n",
    "#-------------------------\n",
    "\n",
    "#DeepFace model\n",
    "base_model = Sequential()\n",
    "base_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n",
    "base_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n",
    "base_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n",
    "base_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n",
    "base_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n",
    "base_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n",
    "base_model.add(Flatten(name='F0'))\n",
    "base_model.add(Dense(4096, activation='relu', name='F7'))\n",
    "base_model.add(Dropout(rate=0.5, name='D0'))\n",
    "base_model.add(Dense(8631, activation='softmax', name='F8'))\n",
    "\n",
    "base_model.load_weights(\"E:/25. Face Recognition/weight/VGGFace2_DeepFace_weights_val-0.9034.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'database/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fc0633ef1821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0memployees\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memployee_pictures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0memployee\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'database/%s.jpg'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0memployee\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'database/'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Drop F8 and D0 layers. F7 is the representation layer.\n",
    "model = Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n",
    "\n",
    "#------------------------\n",
    "def l2_normalize(x):\n",
    "\treturn x / np.sqrt(np.sum(np.multiply(x, x)))\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "\teuclidean_distance = source_representation - test_representation\n",
    "\teuclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "\teuclidean_distance = np.sqrt(euclidean_distance)\n",
    "\treturn euclidean_distance\n",
    "\n",
    "#------------------------\t\n",
    "\n",
    "#put your employee pictures in this path as name_of_employee.jpg\n",
    "employee_pictures = \"database/\"\n",
    "\n",
    "employees = dict()\n",
    "\n",
    "for file in listdir(employee_pictures):\n",
    "\temployee, extension = file.split(\".\")\n",
    "\timg_path = 'database/%s.jpg' % (employee)\n",
    "\timg = detectFace(img_path)\n",
    "\t\n",
    "\trepresentation = model.predict(img)[0]\n",
    "\t\n",
    "\temployees[employee] = representation\n",
    "\t\n",
    "print(\"employee representations retrieved successfully\")\n",
    "\n",
    "#------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam\n",
    "\n",
    "while(True):\n",
    "\tret, img = cap.read()\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #discard small detected faces\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\tdetected_face = cv2.resize(detected_face, target_size) #resize to 152x152\n",
    "\t\t\t\n",
    "\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\timg_pixels /= 255\n",
    "\t\t\t\n",
    "\t\t\tcaptured_representation = model.predict(img_pixels)[0]\n",
    "\t\t\t\n",
    "\t\t\tdistances = []\n",
    "\t\t\t\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tsource_representation = employees[i]\n",
    "\t\t\t\t\n",
    "\t\t\t\tdistance = findEuclideanDistance(l2_normalize(captured_representation), l2_normalize(source_representation))\n",
    "\t\t\t\tdistances.append(distance)\n",
    "\t\t\t\n",
    "\t\t\tis_found = False; index = 0\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tif index == np.argmin(distances):\n",
    "\t\t\t\t\tif distances[index] <= 0.70:\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tprint(\"detected: \",employee_name, \"(\",distances[index],\")\")\n",
    "\t\t\t\t\t\temployee_name = employee_name.replace(\"_\", \"\")\n",
    "\t\t\t\t\t\tsimilarity = distances[index]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tis_found = True\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\t\t\n",
    "\t\t\tif is_found:\n",
    "\t\t\t\tdisplay_img = cv2.imread(\"database/%s.jpg\" % employee_name)\n",
    "\t\t\t\tpivot_img_size = 112\n",
    "\t\t\t\tdisplay_img = cv2.resize(display_img, (pivot_img_size, pivot_img_size))\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tresolution_x = img.shape[1]; resolution_y = img.shape[0]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tlabel = employee_name+\" (\"+\"{0:.2f}\".format(similarity)+\")\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n",
    "\t\t\t\t\t\t#top right\n",
    "\t\t\t\t\t\timg[y - pivot_img_size:y, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y), (x+3*int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+3*int(w/4), y-int(pivot_img_size/2)), (x+w, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\telif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#bottom left\n",
    "\t\t\t\t\t\timg[y+h:y+h+pivot_img_size, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y+h), (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)), (x, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#top left\n",
    "\t\t\t\t\t\timg[y-pivot_img_size:y, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y), (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)), (x, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif x+w+pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n",
    "\t\t\t\t\t\t#bottom righ\n",
    "\t\t\t\t\t\timg[y+h:y+h+pivot_img_size, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y+h), (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)), (x+w, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(\"exception occured: \", str(e))\n",
    "\t\t\t\n",
    "\tcv2.imshow('img',img)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "\t\tbreak\n",
    "\t\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
